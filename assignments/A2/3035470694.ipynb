{"cells":[{"cell_type":"markdown","metadata":{"id":"BHxyiE0JTZxp"},"source":["# Assignment 2\n","You should submit the **UniversityNumber.ipynb** file and your final prediction file **UniversityNumber.test.out** to moodle. Make sure your code does not use your local files and that the results are reproducible. Before submitting, please **run your notebook and keep all running logs** so that we can check."]},{"cell_type":"markdown","metadata":{"id":"cmTXalrJTZxx"},"source":["## 1 Data\n","\n","We will conduct experiments on Conll2003, which contains 14041 sentences, and each sentence is an\u0002notated with the corresponding named entity tags. You can download the dataset from the following\n","link: https://data.deepai.org/conll2003.zip. We only focus on the token and NER tags, which are\n","the first and last columns in the dataset. The dataset is in the IOB format, which is a common format\n","for named entity recognition. The IOB format 1 is a simple way to represent the named entity tags. For\n","example, the sentence “I went to New York City last week” is annotated as follows:\n","\n","    I O\n","    went O\n","    to O\n","    New B-LOC\n","    York I-LOC\n","    City I-LOC\n","    last O\n","    week O"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"PsUJfgqITZx0","executionInfo":{"status":"ok","timestamp":1668500080265,"user_tz":-480,"elapsed":489,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}}},"outputs":[],"source":["def load_data():\n","    # load data\n","    import os\n","    import numpy as np\n","\n","    data_dir = os.path.join(os.getcwd(), \"data\")\n","    train_path = os.path.join(data_dir, 'train.txt')\n","    valid_path = os.path.join(data_dir, 'valid.txt')\n","    test_path  = os.path.join(data_dir, 'test.txt')\n","\n","    with open(train_path, 'r', encoding=\"utf-8\") as f:\n","        train_raw = [l.strip() for l in f.readlines()]\n","        train = list()\n","        start_of_sentence = 0\n","        for i in range(len(train_raw)):\n","            if train_raw[i] == '': # end of sentence\n","                sent = list()\n","                tags = list()\n","                for l in train_raw[start_of_sentence:i]:\n","                    l = l.split(' ')\n","                    sent.append(l[0])\n","                    tags.append(l[-1])\n","                train.append((sent, tags))\n","                start_of_sentence = i+1\n","\n","    with open(valid_path, 'r', encoding=\"utf-8\") as f:\n","        valid_raw = [l.strip() for l in f.readlines()]\n","        valid = list()\n","        start_of_sentence = 0\n","        for i in range(len(valid_raw)):\n","            if valid_raw[i] == '': # end of sentence\n","                sent = list()\n","                tags = list()\n","                for l in valid_raw[start_of_sentence:i]:\n","                    l = l.split(' ')\n","                    sent.append(l[0])\n","                    tags.append(l[-1])\n","                valid.append((sent, tags))\n","                start_of_sentence = i+1\n","    with open(test_path, 'r', encoding=\"utf-8\") as f:\n","        test_raw = [l.strip() for l in f.readlines()]\n","        test = list()\n","        start_of_sentence = 0\n","        for i in range(len(test_raw)):\n","            if test_raw[i] == '': # end of sentence\n","                sent = list()\n","                tags = list()\n","                for l in test_raw[start_of_sentence:i]:\n","                    l = l.split(' ')\n","                    sent.append(l[0])\n","                    tags.append(l[-1])\n","                test.append((sent, tags))\n","                start_of_sentence = i+1\n","    \n","    return train, valid, test"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"y-l530wXTZx3","executionInfo":{"status":"ok","timestamp":1668500081229,"user_tz":-480,"elapsed":466,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}}},"outputs":[],"source":["train, valid, test = load_data()\n","# print(train)\n","# print(valid)\n","# print(test)"]},{"cell_type":"markdown","metadata":{"id":"ohtvrOI6TZx4"},"source":["## 2 Tagger\n","    You will train your tagger on the train set and evaluate it on the dev set. And then, you may tune the\n","    hyperparameters of your tagger to get the best performance on the dev set. Finally, you will evaluate\n","    your tagger on the test set to get the final performance.\n","\n","    https://en.wikipedia.org/wiki/Inside–outside–beginning_(tagging)\n","\n","    There are some key points you should pay attention to:\n","    • You will batch the sentences in the dataset to accelerate the training process. To batch the sentences, you may need to pad the sentences to the same length.\n","    • You are free to design the model architecture with (Bi)LSTM or Transformer unit for each part, but please do not use any pretrained weights in your basic taggers.\n","    • You will adjust the hyperparameters of your tagger to get the best performance on the dev set. The hyperparameters include the learning rate, batch size, the number of hidden units, the number of\n","    layers, the dropout rate, etc.\n","    • You will use seqeval to evaluate your tagger on the dev set and the test set.\n"]},{"cell_type":"markdown","metadata":{"id":"eoXmuUzvTZx5"},"source":["### 2.1 LSTM Tagger\n","    We will first use an LSTM tagger to solve the NER problem. There is a very simple implementation of the\n","    LSTM tagger on PyTorch website https://pytorch.org/tutorials/beginner/nlp/sequence_models_\n","    tutorial.html. You can refer to this implementation to implement your LSTM tagger.\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oG7tAkhvTZx7","executionInfo":{"status":"ok","timestamp":1668500084494,"user_tz":-480,"elapsed":3266,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}},"outputId":"a9a9582a-de65-4657-8987-805b53db0340"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fcbf9ed9130>"]},"metadata":{},"execution_count":5}],"source":["# Author: Robert Guthrie\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","torch.manual_seed(1)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qy_fllCCTZx8","executionInfo":{"status":"ok","timestamp":1668500084495,"user_tz":-480,"elapsed":14,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}},"outputId":"54bc02bc-bcfd-49f8-8cac-fe755b8d5ec9"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[-0.0187,  0.1713, -0.2944]],\n","\n","        [[-0.3521,  0.1026, -0.2971]],\n","\n","        [[-0.3191,  0.0781, -0.1957]],\n","\n","        [[-0.1634,  0.0941, -0.1637]],\n","\n","        [[-0.3368,  0.0959, -0.0538]]], grad_fn=<StackBackward0>)\n","(tensor([[[-0.3368,  0.0959, -0.0538]]], grad_fn=<StackBackward0>), tensor([[[-0.9825,  0.4715, -0.0633]]], grad_fn=<StackBackward0>))\n"]}],"source":["lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n","inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n","\n","# initialize the hidden state.\n","hidden = (torch.randn(1, 1, 3),\n","          torch.randn(1, 1, 3))\n","for i in inputs:\n","    # Step through the sequence one element at a time.\n","    # after each step, hidden contains the hidden state.\n","    out, hidden = lstm(i.view(1, 1, -1), hidden)\n","\n","# alternatively, we can do the entire sequence all at once.\n","# the first value returned by LSTM is all of the hidden states throughout\n","# the sequence. the second is just the most recent hidden state\n","# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n","# The reason for this is that:\n","# \"out\" will give you access to all hidden states in the sequence\n","# \"hidden\" will allow you to continue the sequence and backpropagate,\n","# by passing it as an argument  to the lstm at a later time\n","# Add the extra 2nd dimension\n","inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n","hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # clean out hidden state\n","out, hidden = lstm(inputs, hidden)\n","print(out)\n","print(hidden)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-y-fzjY6TZx9","executionInfo":{"status":"ok","timestamp":1668500084496,"user_tz":-480,"elapsed":10,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}},"outputId":"e6627c6d-7364-45ef-b616-876eb755df84"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'O': 0, 'B-ORG': 1, 'B-MISC': 2, 'B-PER': 3, 'I-PER': 4, 'B-LOC': 5, 'I-ORG': 6, 'I-MISC': 7, 'I-LOC': 8}\n"]}],"source":["# prepare the data\n","def prepare_sequence(seq, to_ix):\n","    idxs = [to_ix[w] for w in seq]\n","    return torch.tensor(idxs, dtype=torch.long)\n","\n","# Tags are: DET - determiner; NN - noun; V - verb\n","# For example, the word \"The\" is a determiner\n","training_data = train\n","word_to_ix = {}\n","tag_to_ix = {}  # Assign each tag with a unique index\n","# For each words-list (sentence) and tags-list in each tuple of training_data\n","for sent, tags in training_data:\n","    for word in sent:\n","        if word not in word_to_ix:  # word has not been assigned an index yet\n","            word_to_ix[word] = len(word_to_ix)  # Assign each word with a unique index\n","    for word in tags:\n","        if word not in tag_to_ix:  # word has not been assigned an index yet\n","            tag_to_ix[word] = len(tag_to_ix)  # Assign each word with a unique index\n","\n","# print(word_to_ix)\n","print(tag_to_ix)\n","\n","# These will usually be more like 32 or 64 dimensional.\n","# We will keep them small, so we can see how the weights change as we train.\n","EMBEDDING_DIM = 64\n","HIDDEN_DIM = 64"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ssdHUA34TZx-","executionInfo":{"status":"ok","timestamp":1668500084496,"user_tz":-480,"elapsed":7,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}}},"outputs":[],"source":["# create the model\n","class LSTMTagger(nn.Module):\n","\n","    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n","        super(LSTMTagger, self).__init__()\n","        self.hidden_dim = hidden_dim\n","\n","        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n","\n","        # The LSTM takes word embeddings as inputs, and outputs hidden states\n","        # with dimensionality hidden_dim.\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n","\n","        # The linear layer that maps from hidden state space to tag space\n","        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n","\n","    def forward(self, sentence):\n","        embeds = self.word_embeddings(sentence)\n","        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n","        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n","        tag_scores = F.log_softmax(tag_space, dim=1)\n","        return tag_scores"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z40clRaPTZyA","executionInfo":{"status":"ok","timestamp":1668501101412,"user_tz":-480,"elapsed":1016923,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}},"outputId":"51a0b96c-f193-47f0-825c-8dad68693d88"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 0, training_loss 8150.593004939059\n","epoch: 1, training_loss 4838.667345512054\n","epoch: 2, training_loss 3587.970861072104\n","epoch: 3, training_loss 2803.0519827813796\n","epoch: 4, training_loss 2252.403670841025\n","epoch: 5, training_loss 1839.448276670148\n","epoch: 6, training_loss 1521.7534741458726\n","epoch: 7, training_loss 1274.8545294019789\n","epoch: 8, training_loss 1075.08321024802\n","epoch: 9, training_loss 918.4380268431189\n","epoch: 10, training_loss 797.5410091248125\n","epoch: 11, training_loss 694.8225520043816\n","epoch: 12, training_loss 611.3298693435916\n","epoch: 13, training_loss 541.2580060195838\n","epoch: 14, training_loss 485.05496011728786\n"]}],"source":["# train the model\n","model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n","loss_function = nn.NLLLoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.1)\n","\n","# See what the scores are before training\n","# Note that element i,j of the output is the score for tag j for word i.\n","# Here we don't need to train, so the code is wrapped in torch.no_grad()\n","with torch.no_grad():\n","    inputs = prepare_sequence(training_data[1][0], word_to_ix)\n","    tag_scores = model(inputs)\n","    # print(tag_scores)\n","\n","training_losses = []\n","for epoch in range(15):  # again, normally you would NOT do 300 epochs, it is toy data\n","    training_loss = 0.0\n","    for sentence, tags in training_data:\n","        # Step 1. Remember that Pytorch accumulates gradients.\n","        # We need to clear them out before each instance\n","        model.zero_grad()\n","\n","        # Step 2. Get our inputs ready for the network, that is, turn them into\n","        # Tensors of word indices.\n","        sentence_in = prepare_sequence(sentence, word_to_ix)\n","        targets = prepare_sequence(tags, tag_to_ix)\n","\n","        # Step 3. Run our forward pass.\n","        tag_scores = model(sentence_in)\n","\n","        # Step 4. Compute the loss, gradients, and update the parameters by\n","        #  calling optimizer.step()\n","        loss = loss_function(tag_scores, targets)\n","        training_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","    training_losses.append(training_loss)\n","    print(f'epoch: {epoch}, training_loss {training_loss}')"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"mPqhtJJ_TZyA","executionInfo":{"status":"ok","timestamp":1668501101412,"user_tz":-480,"elapsed":18,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}}},"outputs":[],"source":["def calculate_accuracy(model, data, tags, words):\n","    \n","    for s in range(len(data)):\n","        # print(data[s])\n","        for w in range(len(data[s][0])):\n","            # print(data[s][0][w])\n","            if data[s][0][w] not in words:  # word has not been assigned an index yet\n","                data[s][0][w] = '.'\n","    \n","    correct = 0\n","    # print(tags)\n","    with torch.no_grad():\n","        for x, y in data:\n","            inputs = prepare_sequence(x, words)\n","            tag_scores = model(inputs)\n","            # print(x)\n","\n","            idx = np.argmax(tag_scores, axis=1)\n","            # print(idx)\n","            pred_tag = [tags[i] for i in idx]\n","            # print(\"predicted result: \", pred_tag)\n","            # print(\"ground truth:     \", y)\n","\n","            correct += sum([y==pred_tag])\n","    \n","    return correct/len(data)\n","   "]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dXDxcKHmTZyB","executionInfo":{"status":"ok","timestamp":1668501114512,"user_tz":-480,"elapsed":13118,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}},"outputId":"898ded80-f8f4-4413-a001-07ef146e76d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy of the model in train data:  0.864616000533796\n","accuracy of the model in valid data:  0.53866128101558\n","accuracy of the model in test data:  0.4554831704668838\n"]}],"source":["# print(tag_to_ix.keys())\n","tags = np.array([tag for tag in tag_to_ix])\n","\n","acc_train = calculate_accuracy(model, train, tags, word_to_ix)\n","print(\"accuracy of the model in train data: \", acc_train)\n","\n","acc_valid = calculate_accuracy(model, valid, tags, word_to_ix)\n","print(\"accuracy of the model in valid data: \", acc_valid)\n","\n","acc_test = calculate_accuracy(model, test, tags, word_to_ix)\n","print(\"accuracy of the model in test data: \", acc_test)"]},{"cell_type":"markdown","metadata":{"id":"8j8K4JS3TZyB"},"source":["### 2.2 Transformer Tagger\n","    We will also use Transformer to solve the NER problem. You can refer to the following link to implement\n","    your Transformer tagger: https://pytorch.org/tutorials/beginner/transformer_tutorial.html."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"WDLPfLgXTZyC","executionInfo":{"status":"ok","timestamp":1668501114513,"user_tz":-480,"elapsed":18,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}}},"outputs":[],"source":["import math\n","from typing import Tuple\n","\n","import torch\n","from torch import nn, Tensor\n","import torch.nn.functional as F\n","from torch.nn import TransformerEncoder, TransformerEncoderLayer\n","from torch.utils.data import dataset\n","\n","class TransformerModel(nn.Module):\n","\n","    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n","                 nlayers: int, dropout: float = 0.5):\n","        super().__init__()\n","        self.model_type = 'Transformer'\n","        self.pos_encoder = PositionalEncoding(d_model, dropout)\n","        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n","        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n","        self.encoder = nn.Embedding(ntoken, d_model)\n","        self.d_model = d_model\n","        self.decoder = nn.Linear(d_model, ntoken)\n","\n","        self.init_weights()\n","\n","    def init_weights(self) -> None:\n","        initrange = 0.1\n","        self.encoder.weight.data.uniform_(-initrange, initrange)\n","        self.decoder.bias.data.zero_()\n","        self.decoder.weight.data.uniform_(-initrange, initrange)\n","\n","    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n","        \"\"\"\n","        Args:\n","            src: Tensor, shape [seq_len, batch_size]\n","            src_mask: Tensor, shape [seq_len, seq_len]\n","\n","        Returns:\n","            output Tensor of shape [seq_len, batch_size, ntoken]\n","        \"\"\"\n","        src = self.encoder(src) * math.sqrt(self.d_model)\n","        src = self.pos_encoder(src)\n","        output = self.transformer_encoder(src, src_mask)\n","        output = self.decoder(output)\n","        return output\n","\n","\n","def generate_square_subsequent_mask(sz: int) -> Tensor:\n","    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n","    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"GP2mRtkgTZyD","executionInfo":{"status":"ok","timestamp":1668501114513,"user_tz":-480,"elapsed":16,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}}},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","\n","    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        position = torch.arange(max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n","        pe = torch.zeros(max_len, 1, d_model)\n","        pe[:, 0, 0::2] = torch.sin(position * div_term)\n","        pe[:, 0, 1::2] = torch.cos(position * div_term)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x: Tensor) -> Tensor:\n","        \"\"\"\n","        Args:\n","            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n","        \"\"\"\n","        x = x + self.pe[:x.size(0)]\n","        return self.dropout(x)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":976},"id":"qBbgUQasTZyD","executionInfo":{"status":"ok","timestamp":1668501301078,"user_tz":-480,"elapsed":186581,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}},"outputId":"b61629e6-5ba9-4b3b-b2f7-d3ffc33321dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchdata\n","  Downloading torchdata-0.5.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[K     |████████████████████████████████| 4.5 MB 35.5 MB/s \n","\u001b[?25hCollecting urllib3>=1.25\n","  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 71.4 MB/s \n","\u001b[?25hCollecting torch==1.13.0\n","  Downloading torch-1.13.0-cp37-cp37m-manylinux1_x86_64.whl (890.2 MB)\n","\u001b[K     |██████████████████████████████  | 834.1 MB 1.3 MB/s eta 0:00:45tcmalloc: large alloc 1147494400 bytes == 0x38ec8000 @  0x7f84a703d615 0x58ead6 0x4f355e 0x4d222f 0x51041f 0x5b4ee6 0x58ff2e 0x510325 0x5b4ee6 0x58ff2e 0x50d482 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4d00fb 0x50cb8d 0x4bac0a 0x538a76 0x590ae5 0x510280 0x5b4ee6 0x58ff2e 0x50d482 0x5b4ee6 0x58ff2e 0x50c4fc 0x58fd37 0x50ca37 0x5b4ee6 0x58ff2e\n","\u001b[K     |████████████████████████████████| 890.2 MB 6.9 kB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata) (2.23.0)\n","Collecting portalocker>=2.0.0\n","  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[K     |████████████████████████████████| 21.0 MB 1.2 MB/s \n","\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[K     |████████████████████████████████| 849 kB 67.3 MB/s \n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[K     |████████████████████████████████| 557.1 MB 12 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.13.0->torchdata) (4.1.1)\n","Collecting nvidia-cublas-cu11==11.10.3.66\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[K     |████████████████████████████████| 317.1 MB 32 kB/s \n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchdata) (0.38.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchdata) (57.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (3.0.4)\n","Collecting urllib3>=1.25\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 74.1 MB/s \n","\u001b[?25hInstalling collected packages: nvidia-cublas-cu11, urllib3, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, torch, portalocker, torchdata\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1+cu113\n","    Uninstalling torch-1.12.1+cu113:\n","      Successfully uninstalled torch-1.12.1+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n","torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n","torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\u001b[0m\n","Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 portalocker-2.6.0 torch-1.13.0 torchdata-0.5.0 urllib3-1.25.11\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["torch"]}}},"metadata":{}}],"source":["%pip install torchdata"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":521},"id":"_gdvy3HUTZyE","executionInfo":{"status":"error","timestamp":1668501301080,"user_tz":-480,"elapsed":37,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}},"outputId":"7f2ecb43-1f66-4833-97db-919db0d31b83"},"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-0cc120859db7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWikiText2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWikiText2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0m_CACHE_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_torch_home\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mag_news\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAG_NEWS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mamazonreviewfull\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAmazonReviewFull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mamazonreviewpolarity\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAmazonReviewPolarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/datasets/ag_news.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_module_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torchdata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorchdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatapipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileOpener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterableWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_hooks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHttpReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchdata/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_extension\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatapipes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mjanitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatapipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjanitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchdata/datapipes/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataChunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctional_datapipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"DataChunk\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"functional_datapipe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"utils\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchdata/datapipes/iter/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mZipper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m )\n\u001b[0;32m---> 32\u001b[0;31m from torchdata.datapipes.iter.load.aisio import (\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mAISFileListerIterDataPipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mAISFileLister\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mAISFileLoaderIterDataPipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mAISFileLoader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchdata/datapipes/iter/load/aisio.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatapipes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional_datapipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatapipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIterDataPipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatapipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStreamWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchdata/datapipes/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatapipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStreamWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_visualization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mjanitor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjanitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchdata/datapipes/utils/_visualization.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatapipes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_ChildDataPipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterDataPipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraverse_dps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'traverse_dps' from 'torch.utils.data.graph' (/usr/local/lib/python3.7/dist-packages/torch/utils/data/graph.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from torchtext.datasets import WikiText2\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","train_iter = WikiText2(split='train')\n","list(train_iter)[3]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j3bnaOPaTZyE","executionInfo":{"status":"aborted","timestamp":1668501301081,"user_tz":-480,"elapsed":35,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}}},"outputs":[],"source":["from torchtext.datasets import WikiText2\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","# train_iter = WikiText2(split='train')\n","tokenizer = get_tokenizer('basic_english')\n","vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n","vocab.set_default_index(vocab['<unk>'])\n","\n","def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n","    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n","    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n","    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n","\n","# train_iter was \"consumed\" by the process of building the vocab,\n","# so we have to create it again\n","train_iter, val_iter, test_iter = WikiText2()\n","train_data = data_process(train_iter)\n","val_data = data_process(val_iter)\n","test_data = data_process(test_iter)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","def batchify(data: Tensor, bsz: int) -> Tensor:\n","    \"\"\"Divides the data into bsz separate sequences, removing extra elements\n","    that wouldn't cleanly fit.\n","\n","    Args:\n","        data: Tensor, shape [N]\n","        bsz: int, batch size\n","\n","    Returns:\n","        Tensor of shape [N // bsz, bsz]\n","    \"\"\"\n","    seq_len = data.size(0) // bsz\n","    data = data[:seq_len * bsz]\n","    data = data.view(bsz, seq_len).t().contiguous()\n","    return data.to(device)\n","\n","batch_size = 20\n","eval_batch_size = 10\n","train_data = batchify(train_data, batch_size)  # shape [seq_len, batch_size]\n","val_data = batchify(val_data, eval_batch_size)\n","test_data = batchify(test_data, eval_batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J9jKTce7TZyF","executionInfo":{"status":"aborted","timestamp":1668501301082,"user_tz":-480,"elapsed":35,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}}},"outputs":[],"source":["bptt = 35\n","def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n","    \"\"\"\n","    Args:\n","        source: Tensor, shape [full_seq_len, batch_size]\n","        i: int\n","\n","    Returns:\n","        tuple (data, target), where data has shape [seq_len, batch_size] and\n","        target has shape [seq_len * batch_size]\n","    \"\"\"\n","    seq_len = min(bptt, len(source) - 1 - i)\n","    data = source[i:i+seq_len]\n","    target = source[i+1:i+1+seq_len].reshape(-1)\n","    return data, target"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d85bwS32TZyF","executionInfo":{"status":"aborted","timestamp":1668501301082,"user_tz":-480,"elapsed":35,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}}},"outputs":[],"source":["ntokens = len(vocab)  # size of vocabulary\n","emsize = 200  # embedding dimension\n","d_hid = 200  # dimension of the feedforward network model in nn.TransformerEncoder\n","nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n","nhead = 2  # number of heads in nn.MultiheadAttention\n","dropout = 0.2  # dropout probability\n","model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ofp08NAPTZyG","executionInfo":{"status":"aborted","timestamp":1668501301083,"user_tz":-480,"elapsed":36,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}}},"outputs":[],"source":["import copy\n","import time\n","\n","criterion = nn.CrossEntropyLoss()\n","lr = 5.0  # learning rate\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n","\n","def train(model: nn.Module) -> None:\n","    model.train()  # turn on train mode\n","    total_loss = 0.\n","    log_interval = 200\n","    start_time = time.time()\n","    src_mask = generate_square_subsequent_mask(bptt).to(device)\n","\n","    num_batches = len(train_data) // bptt\n","    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n","        data, targets = get_batch(train_data, i)\n","        seq_len = data.size(0)\n","        if seq_len != bptt:  # only on last batch\n","            src_mask = src_mask[:seq_len, :seq_len]\n","        output = model(data, src_mask)\n","        loss = criterion(output.view(-1, ntokens), targets)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        if batch % log_interval == 0 and batch > 0:\n","            lr = scheduler.get_last_lr()[0]\n","            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n","            cur_loss = total_loss / log_interval\n","            ppl = math.exp(cur_loss)\n","            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n","                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n","                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n","            total_loss = 0\n","            start_time = time.time()\n","\n","def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n","    model.eval()  # turn on evaluation mode\n","    total_loss = 0.\n","    src_mask = generate_square_subsequent_mask(bptt).to(device)\n","    with torch.no_grad():\n","        for i in range(0, eval_data.size(0) - 1, bptt):\n","            data, targets = get_batch(eval_data, i)\n","            seq_len = data.size(0)\n","            if seq_len != bptt:\n","                src_mask = src_mask[:seq_len, :seq_len]\n","            output = model(data, src_mask)\n","            output_flat = output.view(-1, ntokens)\n","            total_loss += seq_len * criterion(output_flat, targets).item()\n","    return total_loss / (len(eval_data) - 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SwsDBVyZTZyG","executionInfo":{"status":"aborted","timestamp":1668501301084,"user_tz":-480,"elapsed":37,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}}},"outputs":[],"source":["best_val_loss = float('inf')\n","epochs = 1\n","best_model = None\n","\n","for epoch in range(1, epochs + 1):\n","    epoch_start_time = time.time()\n","    train(model)\n","    val_loss = evaluate(model, val_data)\n","    val_ppl = math.exp(val_loss)\n","    elapsed = time.time() - epoch_start_time\n","    print('-' * 89)\n","    print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n","          f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n","    print('-' * 89)\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        best_model = copy.deepcopy(model)\n","\n","    scheduler.step()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2blXuHQQTZyH","executionInfo":{"status":"aborted","timestamp":1668501301084,"user_tz":-480,"elapsed":36,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}}},"outputs":[],"source":["test_loss = evaluate(best_model, test_data)\n","test_ppl = math.exp(test_loss)\n","print('=' * 89)\n","print(f'| End of training | test loss {test_loss:5.2f} | '\n","      f'test ppl {test_ppl:8.2f}')\n","print('=' * 89)"]},{"cell_type":"markdown","metadata":{"id":"GKBIPZoKTZyH"},"source":["### 2.3 Results\n","    Please report your best performance on the test set in the same format as the test.txt file, but replace the ground truth labels with your prediction."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y-KNY7wdTZyH","executionInfo":{"status":"aborted","timestamp":1668501301085,"user_tz":-480,"elapsed":37,"user":{"displayName":"Hi Lo","userId":"02255711645842027696"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"eecfc76fa3750cf2629c769369211f386c60dfd205d50c8d0a6e4dde78012e31"}},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}